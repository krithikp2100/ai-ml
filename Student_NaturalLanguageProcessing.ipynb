{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "NtB_L4mF8E3i",
        "VMlCZ_gtDa6h",
        "Yp0Kt-PS04y-",
        "HCpibGeVgy2i",
        "zcqbg3NSNriB",
        "KtK6uG2fHu2n",
        "yqp-AanZ4v1r"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krithikp2100/ai-ml/blob/main/Student_NaturalLanguageProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiM6gYg0nhkY"
      },
      "source": [
        "<font color=\"red\"><h1><b><u>MAKE A COPY OF THIS NOTEBOOK SO YOUR EDITS ARE SAVED</u></b></h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "<h1>üç≤<b><i> Natural Language Processing: Classifying Yelp Review Sentiment </i></b></h1>"
      ],
      "metadata": {
        "id": "2bH5_hZQGzbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<center> <img src=https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%203%20-%20NLP/Taco%20Bell%20Reviews.png> </center>\n"
      ],
      "metadata": {
        "id": "n5pgFxCkHiKE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svLhCiU3Evm6"
      },
      "source": [
        "\n",
        "\n",
        "Today, we will develop a machine learning model to determine sentiments expressed in Yelp reviews, classifying them as either positive or negative. This introduces the concept of **sentiment analysis**, a form of natural language processing (NLP) that quantifies individuals' opinions (i.e. **good or bad**) from their textual expressions.\n",
        "\n",
        "In this notebook, we'll:\n",
        "\n",
        "1. Explore and manipulate a real Yelp review dataset.\n",
        "2. Learn word embeddings using pre-trained models.\n",
        "3. Preprocess text data with tokenization and vectorization.\n",
        "4. Build and train an RNN for sentiment analysis.\n",
        "5. Evaluate the model's performance on unseen data.\n",
        "\n",
        "**Discussion Prompt:** Consider other contexts in which sentiment analysis could be beneficial for businesses or organizations. How might they leverage this technology?\n",
        "\n",
        "By the end of this, you will not only be able to build a sentiment analysis classifier but also gain insights into the practical challenges and decisions that come with developing AI models.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##**BEFORE RUNNING ANY CODE, please change your Hardware Accelerator to GPU to train faster!**</h2> {\"display-mode\":\"form\"}\n",
        "#@markdown 1. Click on the **Runtime** menu at the top of the screen.\n",
        "#@markdown 2. Click **Change Runtime Type**.\n",
        "#@markdown 3. Choose **T4 GPU** under **Hardware Accelerator**.\n",
        "\n",
        "#@markdown Once you've done that, run this code cell to check you're correctly connected!\n",
        "\n",
        "import tensorflow as tf\n",
        "from IPython.display import Markdown\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "  display(Markdown(\"###‚úÖ GPU connected!\"))\n",
        "else:\n",
        "  display(Markdown(\"\"\"\n",
        "###‚ùå No GPU found!\n",
        "If you're running into GPU limits when you try to switch, here are some suggestions:\n",
        "  - Wait 12-24 hours for the limits to reset.\n",
        "  - Share your copy of the notebook with another Google account that hasn't met the limit, and work through the notebook with that account.\n",
        "  - Look into a paid subscription or paying for compute units as you go.\n",
        "  \"\"\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1zYjzv_qsUpg",
        "outputId": "7598eb61-70f9-42d9-e161-289062f3af97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n###‚ùå No GPU found!\nIf you're running into GPU limits when you try to switch, here are some suggestions:\n  - Wait 12-24 hours for the limits to reset.\n  - Share your copy of the notebook with another Google account that hasn't met the limit, and work through the notebook with that account.\n  - Look into a paid subscription or paying for compute units as you go.\n  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2jS5ThMCEvnC",
        "outputId": "73cdb428-3f44-4185-9bc4-cc82e1e4f14c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m150.9/400.7 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title **üèó Setup Cell** {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "#@markdown **Run this to import libraries and download data!**\n",
        "\n",
        "import pandas as pd   # Great for tables (google spreadsheets, microsoft excel, csv).\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "pd.options.mode.chained_assignment = None #suppress warnings\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "import spacy\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!python -m spacy download en_core_web_lg -q\n",
        "import en_core_web_lg\n",
        "\n",
        "# Inspirit's util file and discussion exercise answer handler\n",
        "!wget -q \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Modules/inspiritai_util.py\"\n",
        "from inspiritai_util import handle_discussion_response\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def cosine(word1, word2):\n",
        "\n",
        "  vector1 = word1.reshape(1, -1)\n",
        "  vector2 = word2.reshape(1, -1)\n",
        "\n",
        "  return cosine_similarity(vector1, vector2)[0][0]\n",
        "\n",
        "#spacy.prefer_gpu()\n",
        "text_to_nlp = en_core_web_lg.load()\n",
        "\n",
        "# Function to convert a word to its vector representation\n",
        "def word2vec(word):\n",
        "    return text_to_nlp(word.lower()).vector\n",
        "\n",
        "\n",
        "# Import our data\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%203%20-%20NLP/yelp_final.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "\n",
        "You can find a more detailed Table of Contents by clicking on the icon on the left sidebar that looks like this: <img src=\"https://drive.google.com/uc?export=view&id=1AGUz4POrRWu_6n5yI_YdO4qFRr41_PzE\" width=20>.\n",
        "\n",
        ">[üìä Milestone 1: Data Exploration](#scrollTo=DQ267zCBOjet)\n",
        "\n",
        ">>[1.1. Introducing the Data](#scrollTo=GOrurZT1gqgl)\n",
        "\n",
        ">>[1.2. Analyzing the Text Data through Word Clouds](#scrollTo=iWbBkEnrgvTJ)\n",
        "\n",
        ">[üè≠ Milestone 2: Processing the Data](#scrollTo=dArbYofKN206)\n",
        "\n",
        ">>[2.1. Word Embeddings Exploration](#scrollTo=DwjdwGBktqTW)\n",
        "\n",
        ">>[2.2. Processing the Input Data](#scrollTo=jGXgWNrWtWAR)\n",
        "\n",
        ">>[2.3. Processing our Output Data](#scrollTo=0bwasn11BfD4)\n",
        "\n",
        ">[üîÑ Milestone 3: Recurrent Neural Networks (RNNs)](#scrollTo=42rl41sUXr0-)\n",
        "\n",
        ">[(Optional) ‚öñÔ∏è Milestone 4: Exploring Impact and Ethics](#scrollTo=HCpibGeVgy2i)\n",
        "\n",
        ">[(Optional Challenge) üßÆ Milestone 5: Linear Algebra and Embeddings](#scrollTo=zcqbg3NSNriB)\n",
        "\n",
        ">[ü§î Knowledge Check](#scrollTo=2e3T609ocyTA)\n",
        "\n",
        ">[üìã Cheat Sheets](#scrollTo=arJN8ZYjpqFz)\n",
        "\n",
        ">>[(Optional reference) Functions](#scrollTo=KtK6uG2fHu2n)\n",
        "\n",
        ">>[(Optional reference) if statements](#scrollTo=yqp-AanZ4v1r)\n",
        "\n"
      ],
      "metadata": {
        "id": "NtB_L4mF8E3i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ267zCBOjet"
      },
      "source": [
        "---\n",
        "---\n",
        "# **üìä Milestone 1: Data Exploration**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Introducing the Data"
      ],
      "metadata": {
        "id": "GOrurZT1gqgl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BLs_2JkEvnw"
      },
      "source": [
        "First, let's start by loading our review data. The data is stored in a file named `yelp_final.csv`. You can see this file for yourself by clicking the folder icon on the left-hand side of the screen. We will use the `read_csv` function from the pandas library to load the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dZ_lymcN_K9"
      },
      "outputs": [],
      "source": [
        "yelp = pd.read_csv('yelp_final.csv')\n",
        "yelp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1. Discussion Exercise"
      ],
      "metadata": {
        "id": "6XxIvS2RDVHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *1. Which column in the dataset represents the user's REVIEW about the restaurant and would be used as the input to our models?*\n",
        "answer_1 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *2. Which column in the dataset can we use to represent the user's SENTIMENT about the restaurant when training our models?*\n",
        "answer_2 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer_1, answer_2)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y9LnT749CCpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional) 1.1.2. Discussion Exercise"
      ],
      "metadata": {
        "id": "VMlCZ_gtDa6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *Notice that the business and user identifiers are not real names but appear as random strings. This technique is known as [hashing](https://medium.com/tech-tales/what-is-hashing-6edba0ebfa67), a common method to ensure privacy.*\n",
        "\n",
        "#@markdown *Discuss why you think real names are not included in this dataset. What are the potential risks of using real names in publicly available data?*\n",
        "answer = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sHAKE7LaDdT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Analyzing the Text Data through Word Clouds"
      ],
      "metadata": {
        "id": "iWbBkEnrgvTJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MExj8roOEvog"
      },
      "source": [
        "Currently, our main focus is on the `'text'` column, which contains the reviews. Let's examine some word clouds describing the text data!\n",
        "\n",
        "Do you know what a word cloud is? If not, run the cell below and take a guess."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la3rUPKgEvoi"
      },
      "outputs": [],
      "source": [
        "#@title {\"display-mode\":\"form\", \"form-width\":\"25%\", \"run\":\"auto\"}\n",
        "#@markdown Choose a number of stars from the dropdown to display the word cloud for reviews with that rating!\n",
        "\n",
        "# Set the number of stars to select reviews\n",
        "num_stars = 1 # @param [\"1\",\"2\",\"3\",\"4\",\"5\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "this_star_text = ''\n",
        "for review in yelp[yelp['stars'] == num_stars]['text'].values:\n",
        "    this_star_text += review + ' '\n",
        "\n",
        "wordcloud = WordCloud()\n",
        "wordcloud.generate_from_text(this_star_text)\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.imshow(wordcloud, interpolation='bilinear');"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1. Discussion Exercise\n",
        "\n",
        "If you're still unsure what a word cloud is showing, each word's size corresponds to how often it shows up in reviews. After looking through the word clouds above, answer the following questions!"
      ],
      "metadata": {
        "id": "3D0yNPMzil-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *1. For each star rating, what words are distinctive to that rating? For example, what words could help you tell that a review was 1 star vs. 5 stars?*\n",
        "answer_1 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *2. Are there any words in the bad reviews that surprise you? What about in the good reviews?*\n",
        "answer_2 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *3. You might notice that some words show up in both good and bad reviews! Why is this happening? Would these be useful for our sentiment analysis?*\n",
        "answer_3 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer_1, answer_2, answer_3)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "r6hrw7s-ilkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpU7nrWTEvov"
      },
      "source": [
        "### 1.2.2. Discussion Exercise\n",
        "\n",
        "Before we start using machine learning models, imagine you're designing a simple system to tell if a review is **positive** or **negative** based only on what words it uses. This is the basis of a rules-based classifier: it uses specific rules you set to make decisions.\n",
        "\n",
        "As a group, come up with set of rules using combinations of words that might help identify the sentiment of a review. Write down your ideas below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxuZyKOKy6Cc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown *1. Describe a combination of words or a pattern that typically indicates a POSITIVE review.*\n",
        "answer_1 = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown *2. Describe a combination of words or a pattern that typically indicates a NEGATIVE review.*\n",
        "answer_2 = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown *3. Do you think the rules you've created will perform well in accurately classifying review sentiments? Why or why not?*\n",
        "answer_3 = \"\" #@param {type:\"string\"}\n",
        "\n",
        "handle_discussion_response(answer_1, answer_2, answer_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional) 1.2.3. Coding Exercise\n",
        "\n",
        "Now it's time to put your rules to the test! Write a function that uses one of the rules you developed to determine whether a review is **positive** or **negative**. We've provided the basic structure of the function below.\n",
        "\n",
        "*Hints/tips:*\n",
        "<details><summary>click to reveal!</summary>\n",
        "\n",
        "- If you're not sure how to write a function, take a look at [the reference](#scrollTo=KtK6uG2fHu2n).\n",
        "\n",
        "- Since the function is called `is_good_review_rules_based()`, it should return `True` if the review is good, and `False` if it's bad.\n",
        "  - Check out the [`if` statement reference](#scrollTo=yqp-AanZ4v1r) if you're stuck!\n",
        "\n",
        "- You can check if a word is in a given string by typing something like `if 'WORD' in TEXT:`\n",
        "\n"
      ],
      "metadata": {
        "id": "Yp0Kt-PS04y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_good_review_rules_based(text):\n",
        "    # You might start with a simple 'if' statement checking for certain words or phrases.\n",
        "    pass  # Remove 'pass' and replace it with your implementation.\n",
        "\n"
      ],
      "metadata": {
        "id": "-YdvhkTR03-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dArbYofKN206"
      },
      "source": [
        "---\n",
        "---\n",
        "# **üè≠ Milestone 2: Processing the Data**\n",
        "\n",
        "As we transition from manually crafting rules to using more sophisticated machine learning techniques, we will prepare our data for analysis using a Recurrent Neural Network (RNN). This type of model is particularly effective for processing sequences, such as text, due to its ability to maintain information across inputs!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Word Embeddings Exploration"
      ],
      "metadata": {
        "id": "DwjdwGBktqTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that the algorithms we use in machine learning require numerical input, so we need some way of converting the words in our reviews to numbers!\n",
        "\n",
        "The usual way we do this is through **word embeddings**, which are lists of numbers that neural networks have learned to describe a word, by looking through text data and seeing how words show up in similar contexts! As an example, take a look at the following sentences:\n",
        "\n",
        "- \"My friend knows how to play _____.\"\n",
        "- \"_____ is my favorite instrument!\"\n",
        "- \"I can't! I have to go to _____ lessons today.\"\n",
        "\n",
        "Words like \"guitar\" and \"piano\" could easily fit in these blanks. When creating word embeddings, we will likely have a lot of data where these two words (and other similar words!) show up in similar places, so we would then make the numbers in their word embeddings more similar.\n"
      ],
      "metadata": {
        "id": "xR9gPxN66Nw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Embedding Visualization\n",
        "\n",
        "If you didn't get the chance during lecture, please take a look at the [Word2Vec Visualization](https://projector.tensorflow.org/)!\n",
        "\n",
        "You can click on any of the dots to see what word it is and what the most similar words are! You can also use the search in the upper right corner to analyze specific words.\n",
        "\n",
        "Once you've tried out a few words, try looking at words that have multiple meanings! What's interesting about their nearest neighbors?"
      ],
      "metadata": {
        "id": "eMFR_sjglmk6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY5fq4YadDC5"
      },
      "source": [
        "### 2.1.1. Coding Exercise\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We will use `en_core_web_md`, a medium-sized Word2Vec model provided by spaCy. This model has been trained on a vast amount of text from the internet, allowing it to understand language by analyzing the words' contexts.\n",
        "\n",
        "Retrieve the word embedding for the word \"student\" using the provided `word2vec` function, which is defined in the set-up cell if you're curious. You can use it like so:\n",
        "\n",
        "```python\n",
        "EMBEDDING = word2vec(WORD_VARIABLE) # using a pre-defined variable\n",
        "EMBEDDING = word2vec(\"WORD\") # using the word directly\n",
        "```\n",
        "\n",
        "Once you have your code working, try changing \"student\" to another word. What changes? What doesn't change?"
      ],
      "metadata": {
        "id": "H22PsHS-8V7c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzpMqkYdYMzD"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "# Define the word you want to analyze\n",
        "word = \"student\" # <- Replace with whatever word you'd like to see the vector of\n",
        "\n",
        "# Retrieve the word embedding vector for the word \"student\"\n",
        "word_embedding = None # <- Replace None with the function call to get the vector\n",
        "\n",
        "# Get the length of the word embedding vector\n",
        "length_word_embedding = None  # <- Replace None with code to calculate the length of the vector\n",
        "\n",
        "### END CODE HERE\n",
        "\n",
        "# Print the word embedding vector and its length\n",
        "print(\"Word Embedding:\", word_embedding)\n",
        "print(\"Length of Word Embedding:\", length_word_embedding)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2euEDp-YMzE"
      },
      "source": [
        "### Similarity Using Word Vectors\n",
        "It's pretty difficult to get much meaning from lists of 300 numbers, so let's take a look at how we can compare words with a single number.\n",
        "\n",
        "Word vectors allow us to quantify how similar two words are by comparing their embeddings (i.e. vectors). To measure this similarity, we use the cosine similarity metric, which can be calculated using the function `cosine(vector1, vector2)` (defined in the set-up cell)\n",
        "\n",
        "![](https://storage.googleapis.com/lds-media/images/cosine-similarity-vectors.original.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GsnUMqQOEn5"
      },
      "source": [
        "### 2.1.2. Coding Exercise\n",
        "\n",
        "In the following code cell, we'll define a function called `similarity()` that will take in two words and return the cosine similarity between them.\n",
        "\n",
        "If you're stuck, unhide the hints below:\n",
        "<details><summary>click to reveal!</summary>\n",
        "\n",
        "- If you're unfamiliar with functions, take a look at [the reference](#scrollTo=KtK6uG2fHu2n)!\n",
        "\n",
        "- Our inputs are words, but we need embeddings to calculate the similarities. How can we convert the words to embeddings and save those values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu5iHeVvYMzF"
      },
      "outputs": [],
      "source": [
        "def similarity(word1, word2):\n",
        "  # This function calculates and returns the cosine similarity between word1 and word2\n",
        "\n",
        "  pass ### <- YOUR CODE HERE: Delete the pass and add your lines of code\n",
        "\n",
        "similarity(\" \", \" \") ### <- YOUR CODE HERE: Fill in the \" \"s with the two words you'd like to compare!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.3. Discussion Exercise"
      ],
      "metadata": {
        "id": "pVOGwDFHiaEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *1. What is a pair of words with a similarity greater than 0.8?*\n",
        "answer_1 = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown *2. What is a pair of words with a similarity less than 0.2?*\n",
        "answer_2 = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown *3. Try guessing what the similarity score for \"black\" and \"white\" is, then compute the similarity. Why might we be getting this score?*\n",
        "answer_3 = \"\" #@param {type:\"string\"}\n",
        "\n",
        "handle_discussion_response(answer_1, answer_2, answer_3)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8e4ygvnYidx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Processing the Input Data\n"
      ],
      "metadata": {
        "id": "jGXgWNrWtWAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code cell will do the following:\n",
        "\n",
        "1. Take the `text` column of the dataset and convert the words in each review to their embeddings.\n",
        "2. Make sure every review is the same length for our model later, by inserting 0s at the beginning until each review is as long as the longest review.\n",
        "\n",
        "If you have time and you're curious on how this is done, feel free to take a look at the code, though it is a bit advanced!"
      ],
      "metadata": {
        "id": "2etQLgjptwJ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zso1fJYg0KC5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Run this to process our input data!\n",
        "\n",
        "### HELPER FUNCTIONS\n",
        "def tokenize_and_embed(text_data):\n",
        "    \"\"\"\n",
        "    Tokenizes the text data and converts it to word embeddings using SpaCy.\n",
        "    Args:\n",
        "        text_data (list): A list of nonempty text strings to be processed.\n",
        "    Returns:\n",
        "        list: A list of lists containing embeddings for each token in each document.\n",
        "    \"\"\"\n",
        "    docs = list(text_to_nlp.pipe(text_data))\n",
        "    embeddings = [[token.vector for token in doc] for doc in docs]\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "def standardize_length(embeddings):\n",
        "    \"\"\"\n",
        "    Ensures all embedding lists are the same length by padding shorter ones with zero vectors.\n",
        "    Args:\n",
        "        embeddings (list): A list of nonempty lists of embeddings.\n",
        "    Returns:\n",
        "        list: A list of lists with padded embeddings to ensure uniform length.\n",
        "    \"\"\"\n",
        "    max_length = max(len(tokens) for tokens in embeddings)\n",
        "    embedding_dim = len(embeddings[0][0])\n",
        "    dtype = np.array(embeddings[0][0]).dtype\n",
        "\n",
        "    padded_embeddings = [\n",
        "        [np.zeros(embedding_dim, dtype=dtype) for _ in range(max_length - len(tokens))] + tokens\n",
        "        for tokens in embeddings\n",
        "    ]\n",
        "\n",
        "    return padded_embeddings\n",
        "\n",
        "\n",
        "### DATA PROCESSING\n",
        "X_text = yelp['text']\n",
        "X_embeddings = tokenize_and_embed(X_text)  # Tokenize and get embeddings\n",
        "X_padded = standardize_length(X_embeddings)  # Standardize lengths\n",
        "X = np.array(X_padded) # Convert to numpy array suitable for model input\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our data processed, we have all of our text data in numerical form! The data is now in the `X` variable for you to use.\n",
        "\n",
        "Run the cell below to see what one of the reviews looks like now, as well as the shape of the dataset."
      ],
      "metadata": {
        "id": "Kefi4471vHNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The first review is now represented as:\")\n",
        "print()\n",
        "print(X[0])\n",
        "print()\n",
        "print(f\"The shape of our dataset is now: {X.shape}\")"
      ],
      "metadata": {
        "id": "peEQWgJNvCJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1. Discussion Exercise"
      ],
      "metadata": {
        "id": "dhhax5BH1zQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *What do these numbers mean? Try matching them to each of the descriptions below, and run the cell to see if you're correct!*\n",
        "\n",
        "number_of_numbers_per_word_embedding = 0 # @param {\"type\":\"integer\"}\n",
        "number_of_tokens_per_review = 0 # @param {\"type\":\"integer\"}\n",
        "number_of_reviews = 0 # @param {\"type\":\"integer\"}\n",
        "\n",
        "if (number_of_reviews, number_of_tokens_per_review, number_of_numbers_per_word_embedding) == X.shape:\n",
        "  print(f\"Correct! That means each review is now represented by {number_of_tokens_per_review * number_of_numbers_per_word_embedding:,} numbers, and our entire dataset is {np.prod(X.shape):,} numbers! \")\n",
        "else:\n",
        "  print(f\"Not quite! As a hint, where else may have you seen {X.shape[0]} and {X.shape[2]} in this notebook?\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "M_tk1Ky5wY4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bwasn11BfD4"
      },
      "source": [
        "## 2.3. Processing our Output Data\n",
        "\n",
        "To simplify our task into a binary classification problem, we will define a new function called `is_good_review` that will translate our 5 stars categories into 2 categories, using the following rule:\n",
        "\n",
        "- `4`, `5` ‚û° `True`\n",
        "- `1`, `2`, `3` ‚û° `False`\n",
        "\n",
        "\n",
        "We've already provided the function definition below. Fill in the `None` with the correct expression to correctly divide the dataset into two goups, good or bad!\n",
        "\n",
        "Feel free to check out the [`if` statement reference](#scrollTo=yqp-AanZ4v1r) if you're stuck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck4iX6PITzHS"
      },
      "outputs": [],
      "source": [
        "def is_good_review(num_stars):\n",
        "    # This function categorizes reviews based on the number of stars.\n",
        "    # It should return True if the review is positive (4 or 5 stars).\n",
        "    # It should return False if the review is negative (1, 2, or 3 stars).\n",
        "\n",
        "    # Replace 'None' with the appropriate condition for a positive review.\n",
        "    if None:  # YOUR CODE HERE\n",
        "        return None # What should this return?\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ_J7L6KtkYQ"
      },
      "outputs": [],
      "source": [
        "# Apply the function to the 'stars' column to create a new 'is_good_review' column.\n",
        "# This column will have a Boolean value where True represents a 'good' review and False represents a 'bad' review.\n",
        "yelp['is_good_review'] = yelp['stars'].apply(is_good_review)\n",
        "\n",
        "# Display the first few rows to verify the changes.\n",
        "yelp.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the data processed, we can finish up with our last step of splitting the data!\n",
        "\n",
        "Remember that we're focusing on the binary problem of whether the review is good or not, but, as an extra challenge after class, you can try editing the later code to try and predict the star value instead"
      ],
      "metadata": {
        "id": "5HKu1IgDKhdk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PThy6pNUEvsA"
      },
      "outputs": [],
      "source": [
        "y = yelp['is_good_review']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42rl41sUXr0-"
      },
      "source": [
        "---\n",
        "---\n",
        "# **üîÑ Milestone 3: Recurrent Neural Networks (RNNs)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now going to explore a special type of neural network called a Recurrent Neural Network (RNN). While we have briefly touched on other types of neural networks before, RNNs are unique because they can process sequences of data in order. This makes them particularly useful for tasks where the sequence or the order of data points is important.\n",
        "\n",
        "\n",
        "**How Do RNNs Work?**\n",
        "\n",
        "<img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/rnn-many-to-many-different-ltr.png?8ca8bafd1eeac4e8c961d9293858407b\" width=\"500\">\n",
        "\n",
        "\n",
        "Unlike traditional neural networks, which treat each input independently, RNNs have loops in them that allow information to persist. In simpler terms, RNNs can remember information about what has been processed so far, enabling them to make predictions based on the sequence of data received.\n",
        "\n",
        "**Examples of RNN Applications:**\n",
        "\n",
        "- **Stock Prices Prediction:** RNNs can predict future stock prices by learning from past stock price trends.\n",
        "- **Language Modeling:** They can predict the next word in a sentence based on the words that came before, which is useful in text auto-completion tools.\n",
        "- **Weather Forecasting:** RNNs can predict future weather conditions by analyzing the patterns in past weather data.\n",
        "\n",
        "RNNs are well-suited and indispensable for many tasks in fields like finance, natural language processing, and meteorology!\n"
      ],
      "metadata": {
        "id": "sPwT08jzcYQv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1zLNp8IRSbp",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Run this to load the RNN Model!\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "class RNNClassifier:\n",
        "    def __init__(self, num_epochs=30, lstm_units=50, dropout_rate=0.7):\n",
        "        self.num_epochs = num_epochs\n",
        "        self.lstm_units = lstm_units\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(self.lstm_units, return_sequences=True))\n",
        "        model.add(Dropout(self.dropout_rate))\n",
        "        model.add(LSTM(self.lstm_units))\n",
        "        model.add(Dropout(self.dropout_rate))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        optimizer = Adam(learning_rate=0.001)\n",
        "        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def fit(self, X_train, y_train, X_val=None, y_val=None, **kwargs):\n",
        "\n",
        "        \"\"\"\n",
        "        Comment is necessary due to how over complicated I made this. - joel\n",
        "\n",
        "        Fits the model to the training data. Supports optional validation data.\n",
        "        If validation data is provided, early stopping is used if not it's not! haha\n",
        "\n",
        "        Args:\n",
        "            X_train (array): Training data features.\n",
        "            y_train (array): Training data labels.\n",
        "            X_val (array, optional): Validation data features.\n",
        "            y_val (array, optional): Validation data labels.\n",
        "            **kwargs: Additional keyword arguments to pass to the model's fit method.\n",
        "\n",
        "        Returns:\n",
        "            A history object containing training history.\n",
        "        \"\"\"\n",
        "\n",
        "        if X_train is None and y_train is None:\n",
        "          print(\"Arguments are none. Retry with correct arguments.\")\n",
        "          return None\n",
        "\n",
        "        callbacks = kwargs.pop('callbacks', [])\n",
        "\n",
        "        if X_val is not None and y_val is not None:\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "            callbacks.append(early_stopping)\n",
        "            return self.model.fit(X_train, y_train, epochs=self.num_epochs, validation_data=(X_val, y_val), callbacks=callbacks, batch_size=32, verbose=1, **kwargs)\n",
        "        else:\n",
        "            return self.model.fit(X_train, y_train, epochs=self.num_epochs, batch_size=32, verbose=1, callbacks=callbacks, **kwargs)\n",
        "\n",
        "    def predict(self, *args, **kwargs):\n",
        "        predictions = self.model.predict(*args, **kwargs).flatten()\n",
        "        return (predictions > 0.5).astype(int)\n",
        "\n",
        "    def predict_proba(self, *args, **kwargs):\n",
        "        return self.model.predict(*args, **kwargs)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        if name != 'predict' and name != 'predict_proba':\n",
        "            return getattr(self.model, name)\n",
        "        else:\n",
        "            raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yANSd0QWWu1"
      },
      "source": [
        "### 3.1.1. Coding Exercise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We've built the RNN model for you! All you need to do is train it using the `.fit()` function."
      ],
      "metadata": {
        "id": "WlIJefYmupeb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK-rAOubzVUi"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE! Replace the nones!\n",
        "rnn = RNNClassifier(num_epochs=15, lstm_units=50, dropout_rate=0.5)\n",
        "rnn.fit(None, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hFMR7NUV84D"
      },
      "source": [
        "### 3.1.2. Coding Exercise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's evaluate our model's accuracy! Your model needs to **predict** the sentiment, and then you'll **calculate the accuracy** using the `accuracy_score()` function. **Which dataset** should you use?"
      ],
      "metadata": {
        "id": "AucDPnsUut25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = None # YOUR CODE HERE\n",
        "accuracy = None # YOUR CODE HERE\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "obd1a2L1I1Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Run this to display the confusion matrix for your model!\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix,\n",
        "                              display_labels=['negative', 'positive'])\n",
        "disp.plot(cmap='Blues');"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nioJDd3wMbpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zct-JZPQaXno"
      },
      "source": [
        "Congratulations - you've trained and tested your model! It's not perfect, but a whole lot better than a coin flip :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiUFnTXrased"
      },
      "source": [
        "### 3.1.3. Discussion Exercise\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy only tells us so much! It's often useful to figure out **what sorts** of mistakes your model makes.\n",
        "\n",
        "Try entering some reviews below and explore:\n",
        "\n",
        "*   What kind of reviews does your model classify correctly? For example, do long or short reviews work better?\n",
        "*   What kind of reviews does your model get wrong? Does it understand sarcasm or other \"tricky\" language?\n",
        "*   Does it seem like your model pays attention to particular words?"
      ],
      "metadata": {
        "id": "WIbUN6Xou2hN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euuR1VWWEvsX"
      },
      "outputs": [],
      "source": [
        "#@title Enter a review to see your model's classification {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "example_review = \"This was a horrible place!\" #@param {type:'string'}\n",
        "\n",
        "# Assuming the functions tokenize_and_embed, standardize_length, and convert_to_array are defined in the same script or imported\n",
        "# First, wrap the example review in a list since our functions expect a list of texts\n",
        "example_reviews = [example_review]\n",
        "\n",
        "# Tokenize and convert the review text to embeddings\n",
        "X_embeddings = tokenize_and_embed(example_reviews)  # Tokenize and get embeddings\n",
        "\n",
        "# Standardize lengths of the embeddings\n",
        "X_padded = standardize_length(X_embeddings)  # Standardize lengths\n",
        "\n",
        "# Convert the padded embeddings into a numpy array suitable for the model\n",
        "X = np.array(X_padded)  # Convert to numpy array suitable for model input\n",
        "\n",
        "prediction = rnn.predict(X)\n",
        "if prediction[0]:\n",
        "  print (\"This was a GOOD review!\")\n",
        "else:\n",
        "  print (\"This was a BAD review!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCpibGeVgy2i"
      },
      "source": [
        "---\n",
        "---\n",
        "# **(Optional) ‚öñÔ∏è Milestone 4: Exploring Impact and Ethics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cAMr90IfcQE"
      },
      "source": [
        "\n",
        "\n",
        "Whenever we explore a new potential use of AI, it is crucial to have a discussion about the **societal and ethical impact** if it were to be implemented at a large scale.\n",
        "\n",
        "*Illustration: erhui1979/iStock*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDboCWKLlh6g"
      },
      "source": [
        "<center> <img src=\"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%203%20-%20NLP/AI%20Ethics.png\"> </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEOJTWJxmEoI"
      },
      "source": [
        "### üìà Who might this AI impact?\n",
        "\n",
        "An important part of incorporating AI into your businesses is discuss how it would impact all areas of business.\n",
        "Let's come up with 3 groups of people that would be impacted by an AI that can classify reviews as positive or negative. We will call these groups `stakeholders`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qISnUEcmumt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "stakeholder1 = '' #@param {type:\"string\"}\n",
        "stakeholder2 = '' #@param {type:\"string\"}\n",
        "stakeholder3 = '' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLzQjhkpgoiY"
      },
      "source": [
        "\n",
        "\n",
        "*   **Discuss**: For each of those stakeholders, what are some benefits of this AI model? What are some drawbacks?\n",
        "\n",
        "\n",
        "> *Hint: What do each of those stakeholders care about?*\n",
        "\n",
        "\n",
        "\n",
        "* **Discuss**: What are some societal outcomes that can occur to if we had a lot of **false positives** (negative reviews misclassified as positive reviews)? How about **false negatives** (positive reviews misclassified as negative reviews)?\n",
        "\n",
        "*   **Discuss**: What are some potential sources of bias?\n",
        "\n",
        "*   **Discuss**: What are some other ethical questions you can come up with?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcqbg3NSNriB"
      },
      "source": [
        "---\n",
        "---\n",
        "# **(Optional Challenge) üßÆ Milestone 5: Linear Algebra and Embeddings**\n",
        "\n",
        "> (Heads-up: this challenge section is math-heavy!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTyeFBh0CbNO"
      },
      "source": [
        "One reason text embeddings are cool is that we can use them to explore connections in meaning between different words, including calculating similarity between words and completing [analogies](http://epsilon-it.utu.fi/wv_demo/).\n",
        "\n",
        "To get started, we'll first create a vocabulary of the most common words from our Yelp reviews dataset. We'll use a technique called the Bag of Words (BOW) model with a Counter Vectorizer, which counts how often each word appears. From this, we'll select the top 500 most frequently used words to form our vocabulary.\n",
        "\n",
        "Next, we'll create a dictionary containing the vectors for all the words in our vocabulary. This dictionary will help us analyze the relationships between words. If you want to use more than 500 words, feel free to change that number!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1obyb1GHppIV"
      },
      "outputs": [],
      "source": [
        "#@title Run this to define our vocabulary builder! {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "def build_vocab_dict(texts, top_n=500):\n",
        "    \"\"\"\n",
        "    Builds a dictionary of the most common words and their embeddings using SpaCy.\n",
        "\n",
        "    Args:\n",
        "        texts (list of str): The list of texts from which to build the vocabulary.\n",
        "        top_n (int): The number of top words to include in the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping words to their embeddings.\n",
        "    \"\"\"\n",
        "    # Tokenize the text and lower case each word\n",
        "    tokens = [word.lower() for text in texts for word in word_tokenize(text)]\n",
        "\n",
        "    # Remove stopwords and non-alphabetic tokens\n",
        "    filtered_tokens = [token for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
        "\n",
        "    # Count the occurrences of each word\n",
        "    word_counts = Counter(filtered_tokens)\n",
        "\n",
        "    # Select the top 'top_n' most common words\n",
        "    most_common_words = [word for word, count in word_counts.most_common(top_n)]\n",
        "\n",
        "    # Create a dictionary for the most common words and their embeddings\n",
        "    vocab_dict = {}\n",
        "    for word in most_common_words:\n",
        "        token = text_to_nlp.vocab[word]\n",
        "        if token.has_vector:  # Check if the token has a vector in the model's vocabulary\n",
        "            vocab_dict[word] = token.vector\n",
        "        else:\n",
        "            # Handle out-of-vocabulary words by assigning a zero vector\n",
        "            embedding_dim = text_to_nlp.vocab.vectors_length\n",
        "            vocab_dict[word] = np.zeros((embedding_dim,))\n",
        "\n",
        "    return vocab_dict\n",
        "\n",
        "# Example usage:\n",
        "# X_text_example = [\"This is the first document.\", \"This document is the second document.\", \"And this is the third one.\"]\n",
        "# vocab_dict = build_vocab_dict(X_text_example)\n",
        "# print(vocab_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHlGBkBKoUPI"
      },
      "outputs": [],
      "source": [
        "vocab_dict = build_vocab_dict(X_text, top_n = 800)\n",
        "\n",
        "for word, vec in vocab_dict.items():\n",
        "  print(word)\n",
        "\n",
        "print ('{} words in our dictionary'.format(len(vocab_dict)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPCcIyTpDuab"
      },
      "source": [
        "### Cosine Similarity\n",
        "Next, let's calculate the similarity between two words, using their Word2Vec representations. As before, we'll use cosine similarity to measure the similarity between our vectors.\n",
        "\n",
        "As an example, imagine we had two three-dimensional vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omAmAv88GZUp"
      },
      "outputs": [],
      "source": [
        "v0 = [2,3,1]\n",
        "v1 = [2,4,1]\n",
        "\n",
        "v0 @ v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owbBQZUgGgjs"
      },
      "source": [
        "Run the code below to plot those vectors, and try changing the numbers above.\n",
        "How can you make a very small angle between the vectors? How can you make a very large angle?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtbbBLgcFmE0"
      },
      "outputs": [],
      "source": [
        "#@title Run this to create an interactive 3D plot {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "#NOTE: Would be extra cool with sliders for the vector coordinates! - DREW\n",
        "#Code from https://stackoverflow.com/questions/47319238/python-plot-3d-vectors\n",
        "import numpy as np\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "def vector_plot(tvects,is_vect=True,orig=[0,0,0]):\n",
        "    \"\"\"Plot vectors using plotly\"\"\"\n",
        "\n",
        "    if is_vect:\n",
        "        if not hasattr(orig[0],\"__iter__\"):\n",
        "            coords = [[orig,np.sum([orig,v],axis=0)] for v in tvects]\n",
        "        else:\n",
        "            coords = [[o,np.sum([o,v],axis=0)] for o,v in zip(orig,tvects)]\n",
        "    else:\n",
        "        coords = tvects\n",
        "\n",
        "    data = []\n",
        "    for i,c in enumerate(coords):\n",
        "        X1, Y1, Z1 = zip(c[0])\n",
        "        X2, Y2, Z2 = zip(c[1])\n",
        "        vector = go.Scatter3d(x = [X1[0],X2[0]],\n",
        "                              y = [Y1[0],Y2[0]],\n",
        "                              z = [Z1[0],Z2[0]],\n",
        "                              marker = dict(size = [0,5],\n",
        "                                            color = ['blue'],\n",
        "                                            line=dict(width=5,\n",
        "                                                      color='DarkSlateGrey')),\n",
        "                              name = 'Vector'+str(i+1))\n",
        "        data.append(vector)\n",
        "\n",
        "    layout = go.Layout(\n",
        "             margin = dict(l = 4,\n",
        "                           r = 4,\n",
        "                           b = 4,\n",
        "                           t = 4)\n",
        "                  )\n",
        "    fig = go.Figure(data=data,layout=layout)\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "vector_plot([v0,v1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0aSqswQvzuP"
      },
      "source": [
        "### üìê Cosine Similarity Formula\n",
        "\n",
        "Cosine similarity measures the cosine of the angle between two non-zero vectors. This is used to assess how close two items are. It ranges from -1 (exactly opposite) to 1 (exactly the same), with 0 typically indicating no similarity.\n",
        "The cosine similarity between two vectors $ \\mathbf{A} $ and $ \\mathbf{B} $ is calculated as follows:\n",
        "\n",
        "$$ \\text{Cosine Similarity} = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{ \\|\\mathbf{A}\\| \\|\\mathbf{B}\\|} $$\n",
        "\n",
        "Where:\n",
        "- $ \\mathbf{A} \\cdot \\mathbf{B} $ is the dot product of the vectors,\n",
        "- $ \\|\\mathbf{A}\\| $ and $ \\|\\mathbf{B}\\| $ are the norms (or magnitudes) of the vectors. Really, this is just another fancy way of saying \"length\".\n",
        "\n",
        "To successfully implement this, here are some helpful hints regarding the functions and libraries you might need:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vomAid3tv-PJ"
      },
      "source": [
        "#### Functions and Methods to Use:\n",
        "1. **`np.dot()` or `@` operator:** Use this to compute the dot product of two vectors. This function takes two arrays and returns their dot product.\n",
        "   \n",
        "   ```python\n",
        "   dot_product = np.dot(vector1, vector2)\n",
        "   # or\n",
        "   dot_product = vector1 @ vector2\n",
        "   ```\n",
        "\n",
        "2. **`np.linalg.norm()`:** This function computes the norm (magnitude) of a vector. You'll need to calculate the norm for both vectors involved in the cosine similarity.\n",
        "\n",
        "   ```python\n",
        "   norm_vector = np.linalg.norm(vector1)\n",
        "   ```\n",
        "   \n",
        "Use these functions to calculate the cosine similarity according to the formula:\n",
        "\n",
        "$$ \\text{Cosine Similarity} = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BMYUC8E1n3Os"
      },
      "outputs": [],
      "source": [
        "#Your code here! Assume the vectors are numpy arrays already!\n",
        "def my_cosine_similarity(vec1, vec2):\n",
        "    dot_product = None #Fill me in\n",
        "    norm_vec1 = None   #Fill me in\n",
        "    norm_vec2 = None   #Fill me in\n",
        "    similarity = None  #Fill me in\n",
        "    return similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUsZqA6zyn54"
      },
      "outputs": [],
      "source": [
        "#@title Run this to check if your function is correct! {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "\n",
        "# Example vectors\n",
        "vector1 = np.array([1, 2, 3])\n",
        "vector2 = np.array([1, 5, 7])\n",
        "\n",
        "# Compute the cosine similarity\n",
        "similarity_score = my_cosine_similarity(vector1, vector2)\n",
        "print(\"Cosine Similarity:\", similarity_score)\n",
        "print(\"Correct answer: 0.9875414397573881\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ2JQmZELItA"
      },
      "source": [
        "## Exercise: Identifying Similar Words Using Your Cosine Similarity Function\n",
        "\n",
        "In this exercise, you will apply your own implementation of cosine similarity to find the most similar word to a given target word in a vocabulary. You‚Äôll be using the `my_cosine_similarity` function that you wrote earlier, leveraging it to compare word vectors and identify the closest matches.\n",
        "\n",
        "### What You'll Do\n",
        "\n",
        "Write a function named `find_most_similar` that utilizes your `my_cosine_similarity` function to determine which word in a predefined vocabulary is most similar to a specified target word. The function should return both the most similar word and its similarity score!\n",
        "\n",
        "### Some Guidelines\n",
        "\n",
        "1. **Check Vocabulary**: Initially, ensure the target word is present in the vocabulary. If it‚Äôs not, the function should notify the user and not proceed with calculations.\n",
        "2. **Calculate Similarity**: Use your `my_cosine_similarity` function to compute the similarity between the target word's vector and each vector in the vocabulary.\n",
        "3. **Track the Highest Score**: As you compute similarities, keep track of the word with the highest similarity score.\n",
        "4. **Return Results**: After checking all words, return the word with the highest similarity score and the score itself.\n",
        "\n",
        "Here's an example of how your code will be used!\n",
        "\n",
        "```python\n",
        "similar_word, similarity_score = find_most_similar('burger')\n",
        "if similar_word is not None:\n",
        "    print(f\"The most similar word to 'burger' is '{similar_word}' with a similarity score of {similarity_score:.2f}.\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwC6EioNJHKR"
      },
      "outputs": [],
      "source": [
        "def find_most_similar(target_word):\n",
        "    # Check if the target word is in the vocabulary dictionary\n",
        "    if target_word not in vocab_dict:\n",
        "        print(\"Word not in dictionary\")\n",
        "        return None, None\n",
        "\n",
        "    # Retrieve the vector for the target word from the vocabulary dictionary\n",
        "    vec1 = vocab_dict[target_word]\n",
        "\n",
        "    # Initialize variables to keep track of the most similar word and the highest similarity score\n",
        "    most_similar_word = None\n",
        "    highest_similarity = -np.inf  # Start with the lowest possible similarity\n",
        "\n",
        "    # Iterate over each word and its vector in the vocabulary dictionary\n",
        "    for word, vec2 in vocab_dict.items():\n",
        "        # YOUR CODE HERE: Calculate the similarity using the my_cosine_similarity function\n",
        "        # Make sure to remove the continue\n",
        "        continue\n",
        "    # Return the most similar word along with the similarity score\n",
        "    return most_similar_word, highest_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSNAwNv3Ru8D"
      },
      "source": [
        "### Let's test your function below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJmAeGIPJA3z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "word = \"eat\" #@param {type:'string'}\n",
        "\n",
        "similar_word, similarity_score = find_most_similar(word)\n",
        "if similar_word is not None:\n",
        "    print(f\"The most similar word to '{word}' is '{similar_word}' with a similarity score of {similarity_score:.2f}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxcyY1YZO9u5"
      },
      "source": [
        "## Using Word Analogies\n",
        "\n",
        "We can use the functions we've built to complete word analogies, similar to the examples found [here](http://epsilon-it.utu.fi/wv_demo/). For instance, consider the analogy:\n",
        "\n",
        "- Breakfast is to bagel as lunch is to ________,\n",
        "\n",
        "This involves a bit of \"word arithmetic\". Suppose $A_1$, $A_2$, and $B_1$ are vectors representing three known words. Our task is to find $B_2$ to complete the analogy:\n",
        "\n",
        "- $A_1$ is to $A_2$ as $B_1$ is to $B_2$.\n",
        "\n",
        "Intuitively, this implies that the vector difference between $A_1$ and $A_2$ should be the same as the vector difference between $B_1$ and $B_2$. Thus, we can express this relationship mathematically as:\n",
        "\n",
        "- $A_1 - A_2 = B_1 - B_2$\n",
        "\n",
        "### Solving for $B_2$:\n",
        "\n",
        "To find $B_2$, we rearrange the above equation:\n",
        "\n",
        "- $B_2 = B_1 - (A_1 - A_2)$\n",
        "\n",
        "This formulation allows us to compute the expected vector for $B_2$ directly by using vector arithmetic. Once we have the vector for $B_2$, we can use our previously developed functions to identify the word whose vector representation is closest to this computed vector. Try it out and explore different analogies!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSMQEm1JQkVZ"
      },
      "outputs": [],
      "source": [
        "# Complete the function below!\n",
        "def find_analogy(word_a1, word_a2, word_b1):\n",
        "    # Retrieve vectors for each word\n",
        "    # Use the word2vec function to get the vector for each word\n",
        "    a1 = word2vec(word_a1)\n",
        "    a2 = word2vec(word_a2)\n",
        "    b1 = word2vec(word_b1)\n",
        "\n",
        "    # if word_a1 not in vocab_dict or word_a2 not in vocab_dict or word_b1 not in vocab_dict:\n",
        "    #   missing = [word for word in [a1, a2, b1] if vec is None]\n",
        "    #   print(f\"Missing vector for: {', '.join(missing)}\")\n",
        "    #   return None, None\n",
        "\n",
        "    # Check if any vectors are None (word not in vocabulary)\n",
        "    # If any of the words are not in the vocabulary, print a message and return None\n",
        "    # if a1 is None or a2 is None or b1 is None:\n",
        "    #     missing = [word for word, vec in zip([word_a1, word_a2, word_b1], [a1, a2, b1]) if vec is None]\n",
        "    #     print(f\"Missing word for: {', '.join(missing)}\")\n",
        "    #     return None, None\n",
        "\n",
        "    # Calculate the expected vector for b2 based on the analogy\n",
        "    # The analogy is: word_a1 is to word_a2 as word_b1 is to what word?\n",
        "    # Calculate vec1 by subtracting the difference between a1 and a2 from b1\n",
        "    vec1 = b1 - (a1 - a2)\n",
        "\n",
        "    # Initialize variables to keep track of the most similar word and the highest similarity score\n",
        "    most_similar_word = None\n",
        "    highest_similarity = -np.inf  # Initialize with None or a very low value\n",
        "\n",
        "    # Iterate over each word and its vector in the vocabulary dictionary\n",
        "    # vocab_dict is a dictionary where keys are words and values are their vectors\n",
        "    for word, vec2 in vocab_dict.items():\n",
        "        # Skip the current word_b1 to avoid trivial matches\n",
        "        if word == word_a2 or word== word_b1:\n",
        "          continue\n",
        "        # Calculate the similarity using the my_cosine_similarity function\n",
        "        # Your code to calculate similarity goes here\n",
        "        similarity = cosine(vec1, vec2)\n",
        "        # print(similarity)\n",
        "        # Update the most similar word and the highest similarity score if the current word is more similar\n",
        "        # Your code to update most_similar_word and highest_similarity goes here\n",
        "        if similarity > highest_similarity:\n",
        "          most_similar_word = word\n",
        "          highest_similarity = similarity\n",
        "          print(most_similar_word)\n",
        "          print(highest_similarity)\n",
        "\n",
        "    # Return the most similar word along with the similarity score\n",
        "    return most_similar_word, highest_similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHmE4xoyQHYN"
      },
      "source": [
        "### Let's test your function to see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbazWL9BPDYQ"
      },
      "outputs": [],
      "source": [
        "worda1 = \"milk\" #@param {type:'string'}\n",
        "worda2 = \"cheese\" #@param {type:'string'}\n",
        "wordb1 = \"lettuce\" #@param {type:'string'}\n",
        "\n",
        "similar_word, similarity_score = find_analogy(worda1, worda2, wordb1)\n",
        "if similar_word is not None:\n",
        "    print(f\"The word analogous to '{wordb1}' in the context of '{worda1}' to '{worda2}' is '{similar_word}', with a similarity score of {similarity_score:.2f}.\")\n",
        "else:\n",
        "    print(f\"No analogous word found for '{wordb1}' in the context of '{worda1}' to '{worda2}'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlDcBn9kQxNR"
      },
      "source": [
        "Word arithmetic doesn't always work perfectly - it's pretty tricky to find good examples! Which can you discover?\n",
        "\n",
        "If you're looking for a way to expand further on this exercise, you can try seeing what happens when you use [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance), another common measurement, instead of cosine similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# **ü§î Knowledge Check**\n",
        "\n",
        "Great job getting through this notebook! If you have time, feel free to go back to the optional sections before this section to delve deeper.\n",
        "\n",
        "Feel free to use the below questions to ensure you've learned everything from this notebook!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2e3T609ocyTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *1. How is a word cloud useful in analyzing text data?*\n",
        "answer_1 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *2. What are word embeddings, and why do we need them?*\n",
        "answer_2 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *3. What can the cosine function tell us about two word embeddings?*\n",
        "answer_3 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *4. Why are we using an Recurrent Neural Network (RNN) for this problem?*\n",
        "answer_4 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer_1, answer_2, answer_3, answer_4)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "trevjP74c3M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# üìã Extra Resources\n",
        "\n",
        "Feel free to use the following cheat sheet as a quick reference!\n",
        "\n",
        "- [Scikit-learn Pipeline Cheat Sheet](https://docs.google.com/document/d/1NK3wvy9pnpg6vab6AkdzLwGSsNf31NSIsrEYz1IVljk/edit?tab=t.53r5m2rr4htd)\n"
      ],
      "metadata": {
        "id": "arJN8ZYjpqFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional reference) Functions"
      ],
      "metadata": {
        "id": "KtK6uG2fHu2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions in Python are blocks of reusable code that perform a specific task. They take input (also called parameters), process it, and often return a result. Functions help organize code, reduce repetition, and make programs easier to read and maintain.\n",
        "\n",
        "### Defining a Function:\n",
        "```python\n",
        "def function_name(inputs):\n",
        "    return result\n",
        "```\n",
        "\n",
        "- **Indentation**: The function body must be indented (typically 4 spaces).\n",
        "- **Parameters**: Functions can accept inputs, which are passed inside the parentheses.\n",
        "- **Return**: Use `return` to return a value. If no `return`, the function returns `None`.\n",
        "\n",
        "\n",
        "### Example:\n",
        "```python\n",
        "def add(a, b):\n",
        "    s = a + b\n",
        "    return s\n",
        "```\n",
        "\n",
        "When Python encounters a function being called, it will see what has previously been defined and run the associated code. In the following example, Python would set `a=2` and `b=3` and run the code above, returning `a+b` (that is, `2+3`, or `5`), which we can then store in a variable.\n",
        "\n",
        "```python\n",
        "result = add(2, 3)  # 5 is stored in result\n",
        "```\n",
        "\n",
        "The functions we've used so far have all been defined for you, but you can define your own whenever you want!"
      ],
      "metadata": {
        "id": "ICzTAu-vG1yI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional reference) `if` statements\n"
      ],
      "metadata": {
        "id": "yqp-AanZ4v1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Syntax:\n",
        "```python\n",
        "if condition:\n",
        "    # code to execute if condition is True\n",
        "```\n",
        "\n",
        "- **Condition**: An expression that evaluates to `True` or `False`.\n",
        "- **Indentation**: The code inside the `if` block must be indented\n",
        "\n",
        "### Example:\n",
        "```python\n",
        "age = 18\n",
        "if age >= 18:\n",
        "    print(\"You are an adult.\")\n",
        "```\n",
        "\n",
        "### `if-else`:\n",
        "```python\n",
        "if condition:\n",
        "    # code if condition is True\n",
        "else:\n",
        "    # code if condition is False\n",
        "```\n",
        "\n",
        "### `if-elif-else`:\n",
        "```python\n",
        "if condition1:\n",
        "    # code if condition1 is True\n",
        "elif condition2:\n",
        "    # code if condition2 is True and condition1 was False\n",
        "else:\n",
        "    # code if both conditions are False\n",
        "```\n"
      ],
      "metadata": {
        "id": "zpgOi8R6H6u3"
      }
    }
  ]
}